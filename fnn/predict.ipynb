{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"tuned_embedding\"\n",
    "root = \"outputs\"\n",
    "load_weights = False # True if you have weights of models trained on all known terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from fnn.modules import fnn_model, data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dl = data_loader.Data_Loader(distance=None, create_data=True, create_tree = True, standardize=True, embedding_name=embedding, k_folds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fnn_model.simpleModel() for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_weights:\n",
    "    for i in range(0,5):\n",
    "        print(i)\n",
    "        models[i].fit_predict(dl.data[i].train_inputs, dl.data[i].train_outputs[i], epochs=300, verbose=0)\n",
    "    weights = [m.model.get_weights() for m in models]\n",
    "    with open(os.path.join(root,embedding,\"weights.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_weights:\n",
    "    with open(os.path.join(root,embedding,\"weights.pickle\"), \"rb\") as f:\n",
    "        weights = pickle.load(f)\n",
    "    for i in range(0,5):\n",
    "        models[i].model.set_weights(weights[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [models[i].model.predict(dl.data[i].inputs_neig) for i in range(0,5)]\n",
    "predictions = [np.reshape(p, len(p)) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl2 = data_loader.Data_Loader(oceans = [0], distance=None, create_data=True, create_tree = True, standardize=False, embedding_name=\"tuned_embedding_1.5M\", k_folds=None).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean = True, with_std = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(np.transpose(dl2.train_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scaler.inverse_transform(np.transpose(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions, columns=[\"O\",\"C\",\"E\",\"A\",\"N\"])\n",
    "df_predictions[\"word\"] = dl.data[0].words_not_ocean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_predictions = pd.read_csv(\"/Users/LM3C3S/Dropbox/Personality_pred/Predizioni/evaluation/predictions.csv\",sep=\";\").iloc[0:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"O\",\"C\",\"E\",\"A\",\"N\"]:\n",
    "    df_predictions[c] = df_predictions[c].apply(lambda x : min(1,x))\n",
    "    df_predictions[c] = df_predictions[c].apply(lambda x : max(-1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"cont\"] = list(range(0,len(df_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"MK_O+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([1,0,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_O-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([-1,0,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_C+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,1,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_C-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,-1,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_E+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,1,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_E-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,-1,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_A+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,1,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_A-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,-1,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_N+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,0,1])), axis=1, raw=True)\n",
    "df_predictions[\"MK_N-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,0,-1])), axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_index = [\"MK_O+\", \"MK_O-\", \"MK_C+\", \"MK_C-\", \"MK_E+\", \"MK_E-\", \"MK_A+\", \"MK_A-\", \"MK_N+\", \"MK_N-\"]\n",
    "ocean = {\"O\":0,\"C\":1,\"E\":2,\"A\":3,\"N\":4}\n",
    "for mk in marker_index:\n",
    "    oc = mk[3:4]\n",
    "    cont_oc = ocean[oc]\n",
    "    df_predictions[mk] = df_predictions[[\"cont\",oc,mk]].apply(lambda x : x[2] if dl.data[cont_oc].is_significant_term(int(x[0]), x[1], cont_oc) else -100, raw=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_excel(os.path.join(root,embedding,\"predictions.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"N+\"\n",
    "df_predictions.sort_values(\"MK_\"+char, ascending=False).head(50)[[\"word\",\"MK_\"+char]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"O\"\n",
    "df_predictions.sort_values(char, ascending=False).head(50)[[\"word\", char]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
