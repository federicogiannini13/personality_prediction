{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"tuned_embedding\"\n",
    "root = \"outputs\"\n",
    "load_weights = False # True if you have weights of models trained on all known terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/LM3C3S/PycharmProjects/personality_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from fnn.modules import fnn_model, data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData_Loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtraits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_neigs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0membedding_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'new_tuned_embedding'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mk_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_prop_holdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstandardize_holdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwords_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m      Class that creates preprocessing objects for different personality traits.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "The init method that creates preprocessing objects for different personality traits.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "traits: list, default: [0, 1, 2, 3, 4]\n",
       "    OCEAN personality traits: O:0, C:1, E:2, A:3, N:4.\n",
       "distance: float, default: None\n",
       "    In the case of coherence test, the distance to which perform the coherence test. Use None if you are not performing coherence test.\n",
       "max_neigs: int, default: None\n",
       "    Maximum number of unknown neighbors to return in the case of distance>0.\n",
       "    Use None or 0 if you want to return all possible neighbors in the select distance.\n",
       "embedding_name: string, default: 'new_tuned_embeddin'\n",
       "    The embedding to be used. There must be a directory containing the embedding in data folder.\n",
       "k_folds: int, default: None\n",
       "    The number of folds in case of k-fold cross-validation. Use None if you are not using K-fold cv.\n",
       "train_prop_holdout: float, default: None\n",
       "    The proportion of training set on the known terms' set, in case of Holdout validation. Use None if you are not using K-fold cv.\n",
       "standardize_holdout: bool, default: True\n",
       "    In case of Holdout validation, use True if you want to standardize targets.\n",
       "shuffle: bool, default: True\n",
       "    True if you want to shuffle data before splitting in train and test.\n",
       "random_state: int, default: 42\n",
       "    The seed of shuffling. Use None if you don't want the experiment to be repeatable.\n",
       "words_to_select: list, default: None\n",
       "    If you want to select only a subset of words, set this parameter. Use None otherwise.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "self.data: list\n",
       "    The list of preprocessing objects. In the i-th position is stored the preprocessing object associated with the i-th trait of traits' list.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/PycharmProjects/personality_prediction/fnn/modules/data_loader.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_loader.Data_Loader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ KNOWN VOCABULARY CREATED\n",
      "____ PREPROCESSING DONE\n",
      "... Initializing the unknown terms' embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Initializing the unknown terms' embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Initializing the unknown terms' embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Initializing the unknown terms' embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Initializing the unknown terms' embedding\n"
     ]
    }
   ],
   "source": [
    "dl = data_loader.Data_Loader(embedding_name=\"tuned_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fnn_model.FNNModel() for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_weights:\n",
    "    for i in range(0,5):\n",
    "        print(i)\n",
    "        models[i].fit_predict(dl.data[i].train_inputs, dl.data[i].train_outputs[i], epochs=300, verbose=0)\n",
    "    weights = [m.model.get_weights() for m in models]\n",
    "    with open(os.path.join(root,embedding,\"weights.pickle\"), \"wb\") as f:\n",
    "        pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_weights:\n",
    "    with open(os.path.join(root,embedding,\"weights.pickle\"), \"rb\") as f:\n",
    "        weights = pickle.load(f)\n",
    "    for i in range(0,5):\n",
    "        models[i].model.set_weights(weights[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [models[i].model.predict(dl.data[i].inputs_neig) for i in range(0,5)]\n",
    "predictions = [np.reshape(p, len(p)) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl2 = data_loader.Data_Loader(oceans = [0], distance=None, create_data=True, create_tree = True, standardize=False, embedding_name=\"tuned_embedding_1.5M\", k_folds=None).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean = True, with_std = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(np.transpose(dl2.train_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scaler.inverse_transform(np.transpose(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions, columns=[\"O\",\"C\",\"E\",\"A\",\"N\"])\n",
    "df_predictions[\"word\"] = dl.data[0].words_not_ocean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_predictions = pd.read_csv(\"/Users/LM3C3S/Dropbox/Personality_pred/Predizioni/evaluation/predictions.csv\",sep=\";\").iloc[0:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"O\",\"C\",\"E\",\"A\",\"N\"]:\n",
    "    df_predictions[c] = df_predictions[c].apply(lambda x : min(1,x))\n",
    "    df_predictions[c] = df_predictions[c].apply(lambda x : max(-1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"cont\"] = list(range(0,len(df_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"MK_O+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([1,0,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_O-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([-1,0,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_C+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,1,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_C-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,-1,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_E+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,1,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_E-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,-1,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_A+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,1,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_A-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,-1,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_N+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,0,1])), axis=1, raw=True)\n",
    "df_predictions[\"MK_N-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,0,-1])), axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_index = [\"MK_O+\", \"MK_O-\", \"MK_C+\", \"MK_C-\", \"MK_E+\", \"MK_E-\", \"MK_A+\", \"MK_A-\", \"MK_N+\", \"MK_N-\"]\n",
    "ocean = {\"O\":0,\"C\":1,\"E\":2,\"A\":3,\"N\":4}\n",
    "for mk in marker_index:\n",
    "    oc = mk[3:4]\n",
    "    cont_oc = ocean[oc]\n",
    "    df_predictions[mk] = df_predictions[[\"cont\",oc,mk]].apply(lambda x : x[2] if dl.data[cont_oc].is_significant_term(int(x[0]), x[1], cont_oc) else -100, raw=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_excel(os.path.join(root,embedding,\"predictions.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"N+\"\n",
    "df_predictions.sort_values(\"MK_\"+char, ascending=False).head(50)[[\"word\",\"MK_\"+char]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"O\"\n",
    "df_predictions.sort_values(char, ascending=False).head(50)[[\"word\", char]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
