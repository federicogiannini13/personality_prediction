{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = \"tuned_embedding_1.5M\"\n",
    "root = \"/Users/LM3C3S/PycharmProjects/personality_prediction/outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/LM3C3S/PycharmProjects/personality_prediction'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from fnn import fnn_model, data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD PERF TUNED EMBEDDING 1.5M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf = pd.read_excel(\"/Users/LM3C3S/PycharmProjects/personality_prediction/outputs/tuned_embedding_1.5M/performances_coerence.xlsx\").iloc[0:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf = df_perf[df_perf[\"distance\"]==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf.groupby(\"fold\").max(\"best_r2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ OCEAN VOCABULARY CREATED\n",
      "____ PREPROCESSING DONE\n",
      "... Creating the embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Creating the embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Creating the embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Creating the embedding\n",
      "____ PREPROCESSING DONE\n",
      "... Creating the embedding\n"
     ]
    }
   ],
   "source": [
    "dl = data_loader.Data_Loader(distance=None, create_data=True, create_tree = True, standardize=True, embedding_name=embedding, k_folds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [fnn_model.simpleModel() for i in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(i)\n",
    "    models[i].fit_predict(dl.data[i].train_inputs, dl.data[i].train_outputs[i], epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [m.model.get_weights() for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(root,embedding,\"weights.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(root,embedding,\"weights.pickle\"), \"rb\") as f:\n",
    "    weights = pickle.load(f)\n",
    "for i in range(0,5):\n",
    "    models[i].model.set_weights(weights[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [models[i].model.predict(dl.data[i].inputs_neig) for i in range(0,5)]\n",
    "predictions = [np.reshape(p, len(p)) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______ OCEAN VOCABULARY CREATED\n",
      "____ PREPROCESSING DONE\n",
      "... Creating the embedding\n"
     ]
    }
   ],
   "source": [
    "dl2 = data_loader.Data_Loader(oceans = [0], distance=None, create_data=True, create_tree = True, standardize=False, embedding_name=\"tuned_embedding_1.5M\", k_folds=None).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean = True, with_std = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(np.transpose(dl2.train_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = scaler.inverse_transform(np.transpose(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(predictions, columns=[\"O\",\"C\",\"E\",\"A\",\"N\"])\n",
    "df_predictions[\"word\"] = dl.data[0].words_not_ocean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_predictions = pd.read_csv(\"/Users/LM3C3S/Dropbox/Personality_pred/Predizioni/evaluation/predictions.csv\",sep=\";\").iloc[0:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"O\",\"C\",\"E\",\"A\",\"N\"]:\n",
    "    df_predictions[c] = df_predictions[c].apply(lambda x : min(1,x))\n",
    "    df_predictions[c] = df_predictions[c].apply(lambda x : max(-1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"cont\"] = list(range(0,len(df_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"MK_O+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([1,0,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_O-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([-1,0,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_C+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,1,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_C-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,-1,0,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_E+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,1,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_E-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,-1,0,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_A+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,1,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_A-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,-1,0])), axis=1, raw=True)\n",
    "df_predictions[\"MK_N+\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,0,1])), axis=1, raw=True)\n",
    "df_predictions[\"MK_N-\"] = df_predictions[[\"O\",\"C\",\"E\",\"A\",\"N\"]].apply(lambda x : 1-dist(x, np.asarray([0,0,0,0,-1])), axis=1, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Creating the known tree\n",
      "... Querying the known tree\n",
      "... Creating the known tree\n",
      "... Querying the known tree\n",
      "... Creating the known tree\n",
      "... Querying the known tree\n",
      "... Creating the known tree\n",
      "... Querying the known tree\n",
      "... Creating the known tree\n",
      "... Querying the known tree\n"
     ]
    }
   ],
   "source": [
    "marker_index = [\"MK_O+\", \"MK_O-\", \"MK_C+\", \"MK_C-\", \"MK_E+\", \"MK_E-\", \"MK_A+\", \"MK_A-\", \"MK_N+\", \"MK_N-\"]\n",
    "ocean = {\"O\":0,\"C\":1,\"E\":2,\"A\":3,\"N\":4}\n",
    "for mk in marker_index:\n",
    "    oc = mk[3:4]\n",
    "    cont_oc = ocean[oc]\n",
    "    df_predictions[mk] = df_predictions[[\"cont\",oc,mk]].apply(lambda x : x[2] if dl.data[cont_oc].is_significant_term(int(x[0]), x[1], cont_oc) else -100, raw=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>A</th>\n",
       "      <th>N</th>\n",
       "      <th>word</th>\n",
       "      <th>cont</th>\n",
       "      <th>MK_O+</th>\n",
       "      <th>MK_O-</th>\n",
       "      <th>MK_C+</th>\n",
       "      <th>MK_C-</th>\n",
       "      <th>MK_E+</th>\n",
       "      <th>MK_E-</th>\n",
       "      <th>MK_A+</th>\n",
       "      <th>MK_A-</th>\n",
       "      <th>MK_N+</th>\n",
       "      <th>MK_N-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007608</td>\n",
       "      <td>0.013631</td>\n",
       "      <td>-0.035440</td>\n",
       "      <td>0.134971</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>!</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.017343</td>\n",
       "      <td>-0.002275</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>-0.023246</td>\n",
       "      <td>-0.044342</td>\n",
       "      <td>0.025889</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>-0.135656</td>\n",
       "      <td>-0.002491</td>\n",
       "      <td>-0.017131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003214</td>\n",
       "      <td>-0.006326</td>\n",
       "      <td>0.014983</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>-0.042307</td>\n",
       "      <td>not</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011040</td>\n",
       "      <td>-0.004662</td>\n",
       "      <td>-0.014113</td>\n",
       "      <td>-0.001560</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>-0.022615</td>\n",
       "      <td>0.115917</td>\n",
       "      <td>-0.118009</td>\n",
       "      <td>-0.048994</td>\n",
       "      <td>0.035034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026095</td>\n",
       "      <td>-0.017712</td>\n",
       "      <td>-0.008838</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>get</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014871</td>\n",
       "      <td>-0.036754</td>\n",
       "      <td>-0.028636</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>-0.019973</td>\n",
       "      <td>-0.002493</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>-0.025985</td>\n",
       "      <td>0.145430</td>\n",
       "      <td>-0.146755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008936</td>\n",
       "      <td>-0.016266</td>\n",
       "      <td>0.121332</td>\n",
       "      <td>0.102384</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>good</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.003893</td>\n",
       "      <td>-0.021541</td>\n",
       "      <td>-0.028691</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.115121</td>\n",
       "      <td>-0.126205</td>\n",
       "      <td>0.093962</td>\n",
       "      <td>-0.109253</td>\n",
       "      <td>-0.001641</td>\n",
       "      <td>-0.023749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057819</td>\n",
       "      <td>-0.044941</td>\n",
       "      <td>-0.090218</td>\n",
       "      <td>0.043459</td>\n",
       "      <td>-0.060051</td>\n",
       "      <td>place</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049548</td>\n",
       "      <td>-0.065193</td>\n",
       "      <td>-0.053033</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>-0.095186</td>\n",
       "      <td>0.084271</td>\n",
       "      <td>0.034558</td>\n",
       "      <td>-0.051625</td>\n",
       "      <td>-0.067286</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59476</th>\n",
       "      <td>0.110391</td>\n",
       "      <td>0.191497</td>\n",
       "      <td>-0.125226</td>\n",
       "      <td>0.063852</td>\n",
       "      <td>-0.264790</td>\n",
       "      <td>submersion</td>\n",
       "      <td>59476</td>\n",
       "      <td>0.041905</td>\n",
       "      <td>-0.165981</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.178635</td>\n",
       "      <td>0.057515</td>\n",
       "      <td>-0.005497</td>\n",
       "      <td>-0.125360</td>\n",
       "      <td>-0.291631</td>\n",
       "      <td>0.219520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59477</th>\n",
       "      <td>-0.065228</td>\n",
       "      <td>-0.044693</td>\n",
       "      <td>-0.232052</td>\n",
       "      <td>0.033362</td>\n",
       "      <td>-0.218086</td>\n",
       "      <td>cool-down</td>\n",
       "      <td>59477</td>\n",
       "      <td>-0.113207</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>-0.094605</td>\n",
       "      <td>-0.009648</td>\n",
       "      <td>-0.254145</td>\n",
       "      <td>0.197086</td>\n",
       "      <td>-0.020808</td>\n",
       "      <td>-0.084205</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59478</th>\n",
       "      <td>-0.453561</td>\n",
       "      <td>0.208981</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>0.170775</td>\n",
       "      <td>0.211875</td>\n",
       "      <td>popolo</td>\n",
       "      <td>59478</td>\n",
       "      <td>-0.493509</td>\n",
       "      <td>0.354768</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.151087</td>\n",
       "      <td>-0.149735</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.051477</td>\n",
       "      <td>-0.321816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59479</th>\n",
       "      <td>-0.113998</td>\n",
       "      <td>-0.069982</td>\n",
       "      <td>0.294792</td>\n",
       "      <td>0.247245</td>\n",
       "      <td>-0.027642</td>\n",
       "      <td>tusk</td>\n",
       "      <td>59479</td>\n",
       "      <td>-0.180968</td>\n",
       "      <td>0.031138</td>\n",
       "      <td>-0.143089</td>\n",
       "      <td>-0.013275</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.105429</td>\n",
       "      <td>-0.054232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59480</th>\n",
       "      <td>-0.204013</td>\n",
       "      <td>0.042055</td>\n",
       "      <td>-0.091014</td>\n",
       "      <td>0.261797</td>\n",
       "      <td>-0.098928</td>\n",
       "      <td>pedialyte</td>\n",
       "      <td>59480</td>\n",
       "      <td>-0.240171</td>\n",
       "      <td>0.150311</td>\n",
       "      <td>-0.022687</td>\n",
       "      <td>-0.101866</td>\n",
       "      <td>-0.145437</td>\n",
       "      <td>0.026362</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-0.152326</td>\n",
       "      <td>0.034525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59481 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              O         C         E         A         N        word   cont  \\\n",
       "0     -0.007608  0.013631 -0.035440  0.134971  0.007392           !      0   \n",
       "1     -0.003214 -0.006326  0.014983  0.117086 -0.042307         not      1   \n",
       "2      0.026095 -0.017712 -0.008838  0.014989  0.146189         get      2   \n",
       "3      0.008936 -0.016266  0.121332  0.102384  0.011195        good      3   \n",
       "4      0.057819 -0.044941 -0.090218  0.043459 -0.060051       place      4   \n",
       "...         ...       ...       ...       ...       ...         ...    ...   \n",
       "59476  0.110391  0.191497 -0.125226  0.063852 -0.264790  submersion  59476   \n",
       "59477 -0.065228 -0.044693 -0.232052  0.033362 -0.218086   cool-down  59477   \n",
       "59478 -0.453561  0.208981 -0.000778  0.170775  0.211875      popolo  59478   \n",
       "59479 -0.113998 -0.069982  0.294792  0.247245 -0.027642        tusk  59479   \n",
       "59480 -0.204013  0.042055 -0.091014  0.261797 -0.098928   pedialyte  59480   \n",
       "\n",
       "          MK_O+     MK_O-       MK_C+       MK_C-       MK_E+       MK_E-  \\\n",
       "0     -0.017343 -0.002275    0.003752   -0.023246   -0.044342    0.025889   \n",
       "1     -0.011040 -0.004662   -0.014113   -0.001560    0.007122   -0.022615   \n",
       "2      0.014871 -0.036754   -0.028636    0.006398   -0.019973   -0.002493   \n",
       "3     -0.003893 -0.021541   -0.028691    0.003435    0.115121   -0.126205   \n",
       "4      0.049548 -0.065193   -0.053033    0.036093   -0.095186    0.084271   \n",
       "...         ...       ...         ...         ...         ...         ...   \n",
       "59476  0.041905 -0.165981 -100.000000 -100.000000   -0.178635    0.057515   \n",
       "59477 -0.113207  0.010900   -0.094605   -0.009648   -0.254145    0.197086   \n",
       "59478 -0.493509  0.354768 -100.000000 -100.000000   -0.151087   -0.149735   \n",
       "59479 -0.180968  0.031138   -0.143089   -0.013275 -100.000000 -100.000000   \n",
       "59480 -0.240171  0.150311   -0.022687   -0.101866   -0.145437    0.026362   \n",
       "\n",
       "            MK_A+       MK_A-       MK_N+       MK_N-  \n",
       "0        0.134073   -0.135656   -0.002491   -0.017131  \n",
       "1        0.115917   -0.118009   -0.048994    0.035034  \n",
       "2        0.003661   -0.025985    0.145430   -0.146755  \n",
       "3        0.093962   -0.109253   -0.001641   -0.023749  \n",
       "4        0.034558   -0.051625   -0.067286    0.051900  \n",
       "...           ...         ...         ...         ...  \n",
       "59476   -0.005497   -0.125360   -0.291631    0.219520  \n",
       "59477   -0.020808   -0.084205 -100.000000 -100.000000  \n",
       "59478 -100.000000 -100.000000    0.051477   -0.321816  \n",
       "59479 -100.000000 -100.000000   -0.105429   -0.054232  \n",
       "59480 -100.000000 -100.000000   -0.152326    0.034525  \n",
       "\n",
       "[59481 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions.to_excel(os.path.join(root,embedding,\"predictions.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>MK_N+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57455</th>\n",
       "      <td>margolies</td>\n",
       "      <td>0.583118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42212</th>\n",
       "      <td>espo</td>\n",
       "      <td>0.582306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50222</th>\n",
       "      <td>così</td>\n",
       "      <td>0.549766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34114</th>\n",
       "      <td>raum</td>\n",
       "      <td>0.540310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33124</th>\n",
       "      <td>alessandra</td>\n",
       "      <td>0.537262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25941</th>\n",
       "      <td>kem</td>\n",
       "      <td>0.536028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11939</th>\n",
       "      <td>digestive</td>\n",
       "      <td>0.523073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41858</th>\n",
       "      <td>rheumatoid</td>\n",
       "      <td>0.513668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49486</th>\n",
       "      <td>romina</td>\n",
       "      <td>0.513081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44080</th>\n",
       "      <td>intractable</td>\n",
       "      <td>0.510297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57785</th>\n",
       "      <td>plaguing</td>\n",
       "      <td>0.502052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46288</th>\n",
       "      <td>wachtel</td>\n",
       "      <td>0.498946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52460</th>\n",
       "      <td>overactive</td>\n",
       "      <td>0.493863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46711</th>\n",
       "      <td>nhc</td>\n",
       "      <td>0.492447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21418</th>\n",
       "      <td>engulf</td>\n",
       "      <td>0.486697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>ivan</td>\n",
       "      <td>0.485314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43237</th>\n",
       "      <td>frasier</td>\n",
       "      <td>0.484467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42819</th>\n",
       "      <td>instability</td>\n",
       "      <td>0.484321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38049</th>\n",
       "      <td>communicable</td>\n",
       "      <td>0.479335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14540</th>\n",
       "      <td>isabel</td>\n",
       "      <td>0.476552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35302</th>\n",
       "      <td>headaches</td>\n",
       "      <td>0.475082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56401</th>\n",
       "      <td>columnist</td>\n",
       "      <td>0.473615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>wondered</td>\n",
       "      <td>0.472487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>bothered</td>\n",
       "      <td>0.471976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9418</th>\n",
       "      <td>toby</td>\n",
       "      <td>0.470832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35500</th>\n",
       "      <td>delores</td>\n",
       "      <td>0.460868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45568</th>\n",
       "      <td>emphysema</td>\n",
       "      <td>0.459924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>irritated</td>\n",
       "      <td>0.455502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32585</th>\n",
       "      <td>inga</td>\n",
       "      <td>0.453372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6302</th>\n",
       "      <td>laughed</td>\n",
       "      <td>0.451612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48971</th>\n",
       "      <td>hedwig</td>\n",
       "      <td>0.450850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56189</th>\n",
       "      <td>swash</td>\n",
       "      <td>0.449730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>visibly</td>\n",
       "      <td>0.448713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8165</th>\n",
       "      <td>leah</td>\n",
       "      <td>0.446945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>yelled</td>\n",
       "      <td>0.446034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48199</th>\n",
       "      <td>gastritis</td>\n",
       "      <td>0.444236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16755</th>\n",
       "      <td>inundated</td>\n",
       "      <td>0.442380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23140</th>\n",
       "      <td>balkan</td>\n",
       "      <td>0.441843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15469</th>\n",
       "      <td>mari</td>\n",
       "      <td>0.440451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25325</th>\n",
       "      <td>leila</td>\n",
       "      <td>0.440098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18721</th>\n",
       "      <td>tocino</td>\n",
       "      <td>0.439673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31992</th>\n",
       "      <td>heckled</td>\n",
       "      <td>0.439497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>rita</td>\n",
       "      <td>0.439418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43321</th>\n",
       "      <td>circulatory</td>\n",
       "      <td>0.438970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36910</th>\n",
       "      <td>dimaggio</td>\n",
       "      <td>0.436289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>worry</td>\n",
       "      <td>0.436175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33787</th>\n",
       "      <td>compadre</td>\n",
       "      <td>0.435230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21305</th>\n",
       "      <td>jumpin</td>\n",
       "      <td>0.434073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>writer</td>\n",
       "      <td>0.433222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>hurt</td>\n",
       "      <td>0.433103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word     MK_N+\n",
       "57455     margolies  0.583118\n",
       "42212          espo  0.582306\n",
       "50222          così  0.549766\n",
       "34114          raum  0.540310\n",
       "33124    alessandra  0.537262\n",
       "25941           kem  0.536028\n",
       "11939     digestive  0.523073\n",
       "41858    rheumatoid  0.513668\n",
       "49486        romina  0.513081\n",
       "44080   intractable  0.510297\n",
       "57785      plaguing  0.502052\n",
       "46288       wachtel  0.498946\n",
       "52460    overactive  0.493863\n",
       "46711           nhc  0.492447\n",
       "21418        engulf  0.486697\n",
       "8583           ivan  0.485314\n",
       "43237       frasier  0.484467\n",
       "42819   instability  0.484321\n",
       "38049  communicable  0.479335\n",
       "14540        isabel  0.476552\n",
       "35302     headaches  0.475082\n",
       "56401     columnist  0.473615\n",
       "9880       wondered  0.472487\n",
       "2503       bothered  0.471976\n",
       "9418           toby  0.470832\n",
       "35500       delores  0.460868\n",
       "45568     emphysema  0.459924\n",
       "3290      irritated  0.455502\n",
       "32585          inga  0.453372\n",
       "6302        laughed  0.451612\n",
       "48971        hedwig  0.450850\n",
       "56189         swash  0.449730\n",
       "6433        visibly  0.448713\n",
       "8165           leah  0.446945\n",
       "4940         yelled  0.446034\n",
       "48199     gastritis  0.444236\n",
       "16755     inundated  0.442380\n",
       "23140        balkan  0.441843\n",
       "15469          mari  0.440451\n",
       "25325         leila  0.440098\n",
       "18721        tocino  0.439673\n",
       "31992       heckled  0.439497\n",
       "6076           rita  0.439418\n",
       "43321   circulatory  0.438970\n",
       "36910      dimaggio  0.436289\n",
       "1272          worry  0.436175\n",
       "33787      compadre  0.435230\n",
       "21305        jumpin  0.434073\n",
       "7093         writer  0.433222\n",
       "1593           hurt  0.433103"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = \"N+\"\n",
    "df_predictions.sort_values(\"MK_\"+char, ascending=False).head(50)[[\"word\",\"MK_\"+char]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char = \"O\"\n",
    "df_predictions.sort_values(char, ascending=False).head(50)[[\"word\", char]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
